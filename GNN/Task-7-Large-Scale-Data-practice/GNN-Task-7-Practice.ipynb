{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GNN-Task-7\n",
    "## 1. Introduction\n",
    "\n",
    "在前面的学习中我们只接触了数据可全部储存于内存的数据集，这些数据集对应的数据集类在创建对象时就将所有数据都加载到内存。然而在一些应用场景中，**数据集规模超级大，我们很难有足够大的内存完全存下所有数据**。因此需要**一个按需加载样本到内存的数据集类**。在此上半节内容中，我们将学习为一个包含上千万个图样本的数据集构建一个数据集类。\n",
    "\n",
    "\n",
    "## 2. Dataset Base Class\n",
    "在PyG中，我们通过继承[`torch_geometric.data.Dataset`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.InMemoryDataset)基类来自定义一个按需加载样本到内存的数据集类。此基类与Torchvision的`Dataset `类的概念密切相关，这与第6节中介绍的`torch_geometric.data.InMemoryDataset`基类是一样的。\n",
    "\n",
    "**继承`torch_geometric.data.InMemoryDataset`基类要实现的方法，继承此基类同样要实现，此外还需要实现以下方法**：\n",
    "\n",
    "- `len()`：返回数据集中的样本的数量。\n",
    "- `get()`：实现加载单个图的操作。注意：在内部，`__getitem__()`返回通过调用`get()`来获取`Data`对象，并根据`transform`参数对它们进行选择性转换。\n",
    "\n",
    "下面让我们通过一个简化的例子看**继承`torch_geometric.data.Dataset`基类的规范**：\n",
    "\n",
    "```python\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, download_url\n",
    "\n",
    "class MyOwnDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, pre_transform=None):\n",
    "        super(MyOwnDataset, self).__init__(root, transform, pre_transform)\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        # list of file names of raw partial graphs\n",
    "        return ['some_file_1', 'some_file_2', ...]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        # list of file names of processed partial graphs\n",
    "        return ['data_1.pt', 'data_2.pt', ...]\n",
    "\n",
    "    def download(self):\n",
    "        # Download to `self.raw_dir`.\n",
    "        path = download_url(url, self.raw_dir)\n",
    "        ...\n",
    "\n",
    "    def process(self):\n",
    "        i = 0\n",
    "        # process each raw file to get corresponding processed file\n",
    "        for raw_path in self.raw_paths:\n",
    "            # Read data from `raw_path`.\n",
    "            data = Data(...)\n",
    "\n",
    "            if self.pre_filter is not None and not self.pre_filter(data):\n",
    "                continue\n",
    "\n",
    "            if self.pre_transform is not None:\n",
    "                data = self.pre_transform(data)\n",
    "\n",
    "            torch.save(data, osp.join(self.processed_dir, 'data_{}.pt'.format(i)))\n",
    "            i += 1\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.processed_file_names)\n",
    "\n",
    "    def get(self, idx):\n",
    "        data = torch.load(osp.join(self.processed_dir, 'data_{}.pt'.format(idx)))\n",
    "        return data\n",
    "\n",
    "```\n",
    "\n",
    "其中，每个`Data`对象在`process()`方法中单独被保存，并在`get()`中通过指定索引进行加载。\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 3. 合并小图组成大图\n",
    "\n",
    "图可以有任意数量的节点和边，它不是规整的数据结构，因此对图数据封装成批的操作与对图像和序列等数据封装成批的操作不同。PyTorch Geometric中采用的将多个图封装成批的方式是，将小图作为连通组件（connected component）的形式合并，构建一个大图。于是小图的邻接矩阵存储在大图邻接矩阵的对角线上。大图的邻接矩阵、属性矩阵、预测目标矩阵分别为：\n",
    "$$\n",
    "\\begin{split}\\mathbf{A} = \\begin{bmatrix} \\mathbf{A}_1 & & \\\\ & \\ddots & \\\\ & & \\mathbf{A}_n \\end{bmatrix}, \\qquad \\mathbf{X} = \\begin{bmatrix} \\mathbf{X}_1 \\\\ \\vdots \\\\ \\mathbf{X}_n \\end{bmatrix}, \\qquad \\mathbf{Y} = \\begin{bmatrix} \\mathbf{Y}_1 \\\\ \\vdots \\\\ \\mathbf{Y}_n \\end{bmatrix}.\\end{split}\n",
    "$$\n",
    "\n",
    "**此方法有以下关键的优势**：\n",
    "\n",
    "- 依靠消息传递方案的GNN运算不需要被修改，因为消息仍然不能在属于不同图的两个节点之间交换。\n",
    "\n",
    "- 没有额外的计算或内存的开销。例如，这个批处理程序的工作完全不需要对节点或边缘特征进行任何填充。请注意，邻接矩阵没有额外的内存开销，因为它们是以稀疏的方式保存的，只保留非零项，即边。\n",
    "\n",
    "通过[`torch_geometric.data.DataLoader`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.DataLoader)类，多个小图被封装成一个大图。[`torch_geometric.data.DataLoader`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.DataLoader)是PyTorch的`DataLoader`的子类，它覆盖了`collate()`函数，该函数定义了一列表的样本是如何封装成批的。因此，所有可以传递给PyTorch `DataLoader`的参数也可以传递给PyTorch Geometric的 `DataLoader`，例如，`num_workers`。\n",
    "\n",
    "\n",
    "## 4. Pairs of Graphs\n",
    "如果你想在一个[`Data`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data)对象中存储多个图，例如用于图对等应用，我们需要确保所有这些图的正确封装成批行为。例如，考虑将两个图，一个源图$G_s$和一个目标图$G_t$，存储在一个[`Data`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data)类中，即\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(edge_index_s=[2, 8], edge_index_t=[2, 6], x_s=[10, 16], x_t=[8, 16])\n",
      "tensor([[0, 0, 0, 0, 5, 5, 5, 5],\n",
      "        [1, 2, 3, 4, 6, 7, 8, 9]])\n",
      "tensor([[0, 0, 0, 4, 4, 4],\n",
      "        [1, 2, 3, 5, 6, 7]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "class PairData(Data):\n",
    "    def __init__(self, edge_index_s, x_s, edge_index_t, x_t):\n",
    "        super(PairData, self).__init__()\n",
    "        # source graph\n",
    "        self.edge_index_s = edge_index_s\n",
    "        self.x_s = x_s\n",
    "        \n",
    "        # target graph\n",
    "        self.edge_index_t = edge_index_t\n",
    "        self.x_t = x_t\n",
    "\n",
    "    def __inc__(self, key, value):\n",
    "        if key == 'edge_index_s':\n",
    "            return self.x_s.size(0)\n",
    "        if key == 'edge_index_t':\n",
    "            return self.x_t.size(0)\n",
    "        else:\n",
    "            return super().__inc__(key, value)\n",
    "\n",
    "\n",
    "\n",
    "edge_index_s = torch.tensor([\n",
    "    [0, 0, 0, 0],\n",
    "    [1, 2, 3, 4],\n",
    "])\n",
    "x_s = torch.randn(5, 16)  # 5 nodes.\n",
    "edge_index_t = torch.tensor([\n",
    "    [0, 0, 0],\n",
    "    [1, 2, 3],\n",
    "])\n",
    "x_t = torch.randn(4, 16)  # 4 nodes.\n",
    "\n",
    "data = PairData(edge_index_s, x_s, edge_index_t, x_t)\n",
    "data_list = [data, data]\n",
    "loader = DataLoader(data_list, batch_size=2)\n",
    "batch = next(iter(loader))\n",
    "\n",
    "print(batch)\n",
    "\n",
    "print(batch.edge_index_s)\n",
    "\n",
    "print(batch.edge_index_t)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在新的维度上做拼接\n",
    "\n",
    "有时，`Data`对象的属性需要在一个新的维度上做拼接（如经典的封装成批），例如，图级别属性或预测目标。具体来说，形状为`[num_features]`的属性列表应该被返回为`[num_examples, num_features]`，而不是`[num_examples * num_features]`。PyTorch Geometric通过在[`__cat_dim__()`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.Data.__cat_dim__)中返回一个[`None`](https://docs.python.org/3/library/constants.html#None)的连接维度来实现这一点。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:The number of nodes in your data object can only be inferred by its edge indices, and hence may result in unexpected batch-wise behavior, e.g., in case there exists isolated nodes. Please consider explicitly setting the number of nodes for this data object by assigning it to data.num_nodes.\n",
      "WARNING:root:The number of nodes in your data object can only be inferred by its edge indices, and hence may result in unexpected batch-wise behavior, e.g., in case there exists isolated nodes. Please consider explicitly setting the number of nodes for this data object by assigning it to data.num_nodes.\n",
      "WARNING:root:The number of nodes in your data object can only be inferred by its edge indices, and hence may result in unexpected batch-wise behavior, e.g., in case there exists isolated nodes. Please consider explicitly setting the number of nodes for this data object by assigning it to data.num_nodes.\n",
      "WARNING:root:The number of nodes in your data object can only be inferred by its edge indices, and hence may result in unexpected batch-wise behavior, e.g., in case there exists isolated nodes. Please consider explicitly setting the number of nodes for this data object by assigning it to data.num_nodes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch(batch=[6], edge_index=[2, 8], foo=[2, 16], ptr=[3])\n"
     ]
    }
   ],
   "source": [
    "class MyData(Data):\n",
    "     def __cat_dim__(self, key, item):\n",
    "         if key == 'foo':\n",
    "             return None\n",
    "         else:\n",
    "             return super().__cat_dim__(key, item)\n",
    "\n",
    "edge_index = torch.tensor([\n",
    "   [0, 1, 1, 2],\n",
    "   [1, 0, 2, 1],\n",
    "])\n",
    "foo = torch.randn(16)\n",
    "\n",
    "data = MyData(edge_index=edge_index, foo=foo)\n",
    "data_list = [data, data]\n",
    "loader = DataLoader(data_list, batch_size=2)\n",
    "batch = next(iter(loader))\n",
    "\n",
    "print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Mini-Batching for large-scale  graph\n",
    "\n",
    "[**PCQM4M-LSC**](https://ogb.stanford.edu/kddcup2021/pcqm4m/)是一个分子图的量子特性回归数据集，它包含了3,803,453个图。\n",
    "\n",
    "注意以下代码依赖于`ogb`包，通过`pip install ogb`命令可安装此包。`ogb`文档可见于[Get Started | Open Graph Benchmark (stanford.edu)](https://ogb.stanford.edu/docs/home/)。\n",
    "\n",
    "在生成一个该数据集类的对象时，程序首先会检查指定的文件夹下是否存在`data.csv.gz`文件，如果不在，则会执行`download`方法，这一过程是在运行`super`类的`__init__`方法中发生的。然后程序继续执行`__init__`方法的剩余部分，读取`data.csv.gz`文件，获取存储图信息的`smiles`格式的字符串，以及回归预测的目标`homolumogap`。我们将由`smiles`格式的字符串转成图的过程在`get()`方法中实现，这样我们在生成一个`DataLoader`变量时，通过指定`num_workers`可以实现并行执行生成多个图。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool, GlobalAttention, Set2Set\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch_geometric.nn import MessagePassing\n",
    "import torch.nn.functional as F\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "\n",
    "\n",
    "### GIN convolution along the graph structure\n",
    "class GINConv(MessagePassing):\n",
    "    def __init__(self, emb_dim):\n",
    "        '''\n",
    "            emb_dim (int): node embedding dimensionality\n",
    "        '''\n",
    "        super(GINConv, self).__init__(aggr = \"add\")\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU(), nn.Linear(emb_dim, emb_dim))\n",
    "        self.eps = nn.Parameter(torch.Tensor([0]))\n",
    "        self.bond_encoder = BondEncoder(emb_dim = emb_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        edge_embedding = self.bond_encoder(edge_attr) # 先将类别型边属性转换为边表征\n",
    "        out = self.mlp((1 + self.eps) *x + self.propagate(edge_index, x=x, edge_attr=edge_embedding))\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return F.relu(x_j + edge_attr)\n",
    "\n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# GNN to generate node embedding\n",
    "class GINNodeEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "        node representations\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_layers, emb_dim, drop_ratio=0.5, JK=\"last\", residual=False):\n",
    "        \"\"\"GIN Node Embedding Module\"\"\"\n",
    "\n",
    "        super(GINNodeEmbedding, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "        # add residual connection or not\n",
    "        self.residual = residual\n",
    "\n",
    "        if self.num_layers < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "        self.atom_encoder = AtomEncoder(emb_dim)\n",
    "\n",
    "        # List of GNNs\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(GINConv(emb_dim))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(emb_dim))\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "        x, edge_index, edge_attr = batched_data.x, batched_data.edge_index, batched_data.edge_attr\n",
    "\n",
    "        # computing input node embedding\n",
    "        h_list = [self.atom_encoder(x)]  # 先将类别型原子属性转化为原子表征\n",
    "        for layer in range(self.num_layers):\n",
    "            h = self.convs[layer](h_list[layer], edge_index, edge_attr)\n",
    "            h = self.batch_norms[layer](h)\n",
    "            if layer == self.num_layers - 1:\n",
    "                # remove relu for the last layer\n",
    "                h = F.dropout(h, self.drop_ratio, training=self.training)\n",
    "            else:\n",
    "                h = F.dropout(F.relu(h), self.drop_ratio, training=self.training)\n",
    "\n",
    "            if self.residual:\n",
    "                h += h_list[layer]\n",
    "\n",
    "            h_list.append(h)\n",
    "\n",
    "        # Different implementations of Jk-concat\n",
    "        if self.JK == \"last\":\n",
    "            node_representation = h_list[-1]\n",
    "        elif self.JK == \"sum\":\n",
    "            node_representation = 0\n",
    "            for layer in range(self.num_layers + 1):\n",
    "                node_representation += h_list[layer]\n",
    "\n",
    "        return node_representation\n",
    "\n",
    "\n",
    "\n",
    "class GINGraphPooling(nn.Module):\n",
    "\n",
    "    def __init__(self, num_tasks=1, num_layers=5, emb_dim=300, residual=False, drop_ratio=0, JK=\"last\", graph_pooling=\"sum\"):\n",
    "        \"\"\"GIN Graph Pooling Module\n",
    "        Args:\n",
    "            num_tasks (int, optional): number of labels to be predicted. Defaults to 1 (控制了图表征的维度，dimension of graph representation).\n",
    "            num_layers (int, optional): number of GINConv layers. Defaults to 5.\n",
    "            emb_dim (int, optional): dimension of node embedding. Defaults to 300.\n",
    "            residual (bool, optional): adding residual connection or not. Defaults to False.\n",
    "            drop_ratio (float, optional): dropout rate. Defaults to 0.\n",
    "            JK (str, optional): 可选的值为\"last\"和\"sum\"。选\"last\"，只取最后一层的结点的嵌入，选\"sum\"对各层的结点的嵌入求和。Defaults to \"last\".\n",
    "            graph_pooling (str, optional): pooling method of node embedding. 可选的值为\"sum\"，\"mean\"，\"max\"，\"attention\"和\"set2set\"。 Defaults to \"sum\".\n",
    "\n",
    "        Out:\n",
    "            graph representation\n",
    "        \"\"\"\n",
    "        super(GINGraphPooling, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "        if self.num_layers < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "        self.gnn_node = GINNodeEmbedding(num_layers, emb_dim, JK=JK, drop_ratio=drop_ratio, residual=residual)\n",
    "\n",
    "        # Pooling function to generate whole-graph embeddings\n",
    "        if graph_pooling == \"sum\":\n",
    "            self.pool = global_add_pool\n",
    "        elif graph_pooling == \"mean\":\n",
    "            self.pool = global_mean_pool\n",
    "        elif graph_pooling == \"max\":\n",
    "            self.pool = global_max_pool\n",
    "        elif graph_pooling == \"attention\":\n",
    "            self.pool = GlobalAttention(gate_nn=nn.Sequential(\n",
    "                nn.Linear(emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU(), nn.Linear(emb_dim, 1)))\n",
    "        elif graph_pooling == \"set2set\":\n",
    "            self.pool = Set2Set(emb_dim, processing_steps=2)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid graph pooling type.\")\n",
    "\n",
    "        if graph_pooling == \"set2set\":\n",
    "            self.graph_pred_linear = nn.Linear(2*self.emb_dim, self.num_tasks)\n",
    "        else:\n",
    "            self.graph_pred_linear = nn.Linear(self.emb_dim, self.num_tasks)\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "        h_node = self.gnn_node(batched_data)\n",
    "\n",
    "        h_graph = self.pool(h_node, batched_data.batch)\n",
    "        output = self.graph_pred_linear(h_graph)\n",
    "\n",
    "        if self.training:\n",
    "            return output\n",
    "        else:\n",
    "            # At inference time, relu is applied to output to ensure positivity\n",
    "            # 因为预测目标的取值范围就在 (0, 50] 内\n",
    "            return torch.clamp(output, min=0, max=50)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Practice with GIN Regression Task using PCQM4M Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/11896 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device:  cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11896/11896 [06:44<00:00, 29.38it/s]\n",
      "100%|██████████| 1487/1487 [00:51<00:00, 28.91it/s]\n",
      "100%|██████████| 11896/11896 [06:40<00:00, 29.72it/s]\n",
      "100%|██████████| 11896/11896 [06:43<00:00, 29.49it/s]\n",
      "100%|██████████| 1487/1487 [00:50<00:00, 29.23it/s]\n",
      "100%|██████████| 11896/11896 [06:43<00:00, 29.51it/s]\n",
      "100%|██████████| 11896/11896 [06:42<00:00, 29.58it/s]\n",
      "100%|██████████| 1487/1487 [00:51<00:00, 28.71it/s]\n",
      "100%|██████████| 11896/11896 [06:40<00:00, 29.74it/s]\n",
      "100%|██████████| 11896/11896 [06:39<00:00, 29.81it/s]\n",
      "100%|██████████| 1487/1487 [00:50<00:00, 29.54it/s]\n",
      "100%|██████████| 11896/11896 [06:40<00:00, 29.68it/s]\n",
      "100%|██████████| 11896/11896 [06:41<00:00, 29.65it/s]\n",
      "100%|██████████| 1487/1487 [00:50<00:00, 29.25it/s]\n",
      "100%|██████████| 11896/11896 [06:40<00:00, 29.67it/s]\n",
      "100%|██████████| 11896/11896 [06:46<00:00, 29.24it/s]\n",
      "100%|██████████| 1487/1487 [00:49<00:00, 29.96it/s]\n",
      "100%|██████████| 11896/11896 [06:38<00:00, 29.83it/s]\n",
      "100%|██████████| 11896/11896 [06:42<00:00, 29.57it/s]\n",
      "100%|██████████| 1487/1487 [00:49<00:00, 29.92it/s]\n",
      "100%|██████████| 11896/11896 [06:41<00:00, 29.63it/s]\n",
      "100%|██████████| 11896/11896 [06:47<00:00, 29.22it/s]\n",
      "100%|██████████| 1487/1487 [00:49<00:00, 29.78it/s]\n",
      "100%|██████████| 11896/11896 [06:39<00:00, 29.76it/s]\n",
      "100%|██████████| 11896/11896 [06:42<00:00, 29.53it/s]\n",
      "100%|██████████| 1487/1487 [00:49<00:00, 30.23it/s]\n",
      "100%|██████████| 11896/11896 [06:42<00:00, 29.56it/s]\n",
      "100%|██████████| 11896/11896 [06:42<00:00, 29.55it/s]\n",
      "100%|██████████| 1487/1487 [00:49<00:00, 29.90it/s]\n",
      "100%|██████████| 11896/11896 [06:35<00:00, 30.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir=runs\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from ogb.utils.mol import smiles2graph\n",
    "from ogb.utils.torch_util import replace_numpy_with_torchtensor\n",
    "from ogb.lsc import PCQM4MEvaluator\n",
    "from ogb.utils.url import download_url, extract_zip\n",
    "from rdkit import RDLogger\n",
    "from torch_geometric.data import Data, Dataset\n",
    "\n",
    "\n",
    "import shutil\n",
    "\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "RDLogger.DisableLog('rdApp.*')\n",
    "\n",
    "class MyPCQM4MDataset(Dataset):\n",
    "\n",
    "    def __init__(self, root):\n",
    "        self.url = 'https://dgl-data.s3-accelerate.amazonaws.com/dataset/OGB-LSC/pcqm4m_kddcup2021.zip'\n",
    "        super(MyPCQM4MDataset, self).__init__(root)\n",
    "\n",
    "        filepath = osp.join(root, 'raw/data.csv.gz')\n",
    "        data_df = pd.read_csv(filepath)\n",
    "        self.smiles_list = data_df['smiles']\n",
    "        self.homolumogap_list = data_df['homolumogap']\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return 'data.csv.gz'\n",
    "\n",
    "    def download(self):\n",
    "        path = download_url(self.url, self.root)\n",
    "        extract_zip(path, self.root)\n",
    "        os.unlink(path)\n",
    "        shutil.move(osp.join(self.root, 'pcqm4m_kddcup2021/raw/data.csv.gz'), osp.join(self.root, 'raw/data.csv.gz'))\n",
    "\n",
    "    def len(self):\n",
    "        return len(self.smiles_list)\n",
    "\n",
    "    def get(self, idx):\n",
    "        smiles, homolumogap = self.smiles_list[idx], self.homolumogap_list[idx]\n",
    "        graph = smiles2graph(smiles)\n",
    "        assert(len(graph['edge_feat']) == graph['edge_index'].shape[1])\n",
    "        assert(len(graph['node_feat']) == graph['num_nodes'])\n",
    "\n",
    "        x = torch.from_numpy(graph['node_feat']).to(torch.int64)\n",
    "        edge_index = torch.from_numpy(graph['edge_index']).to(torch.int64)\n",
    "        edge_attr = torch.from_numpy(graph['edge_feat']).to(torch.int64)\n",
    "        y = torch.Tensor([homolumogap])\n",
    "        num_nodes = int(graph['num_nodes'])\n",
    "        data = Data(x, edge_index, edge_attr, y, num_nodes=num_nodes)\n",
    "        return data\n",
    "\n",
    "    # 获取数据集划分\n",
    "    def get_idx_split(self):\n",
    "        split_dict = replace_numpy_with_torchtensor(torch.load(osp.join(self.root, 'pcqm4m_kddcup2021/split_dict.pt')))\n",
    "        return split_dict\n",
    "\n",
    "    \n",
    "def train(model, optimizer, loss_f, loader, scheduler ,device ):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    total_nodes = 0.\n",
    "    for batch in tqdm(loader):\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch).to(device)\n",
    "        loss = loss_f(out, batch.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        nodes = batch.num_nodes\n",
    "        total_loss += loss.item() * nodes\n",
    "        total_nodes += nodes\n",
    "        scheduler.step()\n",
    "        \n",
    "    return total_loss/total_nodes\n",
    "\n",
    "\n",
    "def evaluate(model, loader, device, evaluator):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for batch in tqdm(loader):\n",
    "        batch = batch.to(device)\n",
    "        out = model(batch).view(-1, ).to(device)\n",
    "        y_true.append(batch.y.view(out.shape).detach().cpu())\n",
    "        y_pred.append(out.detach().cpu())\n",
    "    #convert list to tensor\n",
    "    y_true = torch.cat(y_true, dim=0)\n",
    "    y_pred = torch.cat(y_pred, dim=0)\n",
    "    dic ={'y_true': y_true, \"y_pred\":y_pred}\n",
    "    return evaluator.eval(dic)['mae']\n",
    "        \n",
    "        \n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    dataset = MyPCQM4MDataset('dataset2')\n",
    "    split_data = dataset.get_idx_split()\n",
    "    output_file =open( \"./task-7-runs/logging.txt\" ,\"a\")\n",
    "    from torch_geometric.data import DataLoader\n",
    "    from tqdm import tqdm\n",
    "    train_loader = DataLoader(dataset[split_data['train']], batch_size=256, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(dataset[split_data['valid']], batch_size=256, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(dataset[split_data['test']], batch_size=256, shuffle=True, num_workers=4)\n",
    "    \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"Using device: \",device)\n",
    "    \n",
    "    # loss used to train model, MSE loss\n",
    "    loss_f = torch.nn.MSELoss()\n",
    "    \n",
    "    # evaluator used to evaluate regression output and prediction, MAE (mean absolute error)\n",
    "    evaluator = PCQM4MEvaluator()\n",
    "    \n",
    "    model = GINGraphPooling(num_tasks=1, num_layers=4, emb_dim=300, residual=False, drop_ratio=0.5, JK=\"last\",\n",
    "                 graph_pooling=\"sum\").to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr =1e-3, weight_decay= 1e-3 )\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "    # tensorboard writer\n",
    "    writer = SummaryWriter(log_dir =\"task-7-runs\" )\n",
    "    epochs = 20\n",
    "    for e in range(epochs):\n",
    "        train_loss = train(model, optimizer, loss_f, train_loader, scheduler,device )\n",
    "        \n",
    "        print(f\"Epoch: {e}, Train MAE: {train_loss} \",file=output_file, flush=True)\n",
    "        writer.add_scalar(\"Loss/train\", train_loss, e)\n",
    "        if e%2==0:\n",
    "            val_mae = evaluate(model, val_loader, device, evaluator)\n",
    "            writer.add_scalar(\"MAE/val\", val_mae, e)\n",
    "            print(f\"Epoch: {e}, Valid MAE: {val_mae} \",file=output_file, flush=True)\n",
    "            \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "1. Training MSE Loss\n",
    "<img src=train_loss.png>\n",
    "\n",
    "2. MAE (Mean Absolute Error) for evaluation \n",
    "<img src=val_mae.png>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Reference\n",
    "[1] OGB document: https://ogb.stanford.edu/kddcup2021/pcqm4m/#evaluator\n",
    "\n",
    "[2] `Dataset`类官方文档： [`torch_geometric.data.Dataset`](https://pytorch-geometric.readthedocs.io/en/latest/modules/data.html#torch_geometric.data.InMemoryDataset)\n",
    "\n",
    "[3] 将图样本封装成批（BATCHING）：[ADVANCED MINI-BATCHING](https://pytorch-geometric.readthedocs.io/en/latest/notes/batching.html)\n",
    "\n",
    "[4] 分子图的量子特性回归数据集：[PCQM4M-LSC](https://ogb.stanford.edu/kddcup2021/pcqm4m/)\n",
    "\n",
    "[5] [Get Started | Open Graph Benchmark (stanford.edu)](https://ogb.stanford.edu/docs/home/)\n",
    "\n",
    "[6] Datawhale: https://github.com/datawhalechina/team-learning-nlp/blob/master/GNN/Markdown%E7%89%88%E6%9C%AC/9-1-%E6%8C%89%E9%9C%80%E8%8E%B7%E5%8F%96%E7%9A%84%E6%95%B0%E6%8D%AE%E9%9B%86%E7%B1%BB%E7%9A%84%E5%88%9B%E5%BB%BA.md\n",
    "\n",
    "https://github.com/datawhalechina/team-learning-nlp/blob/master/GNN/Markdown%E7%89%88%E6%9C%AC/9-2-%E5%9B%BE%E9%A2%84%E6%B5%8B%E4%BB%BB%E5%8A%A1%E5%AE%9E%E8%B7%B5.md\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv_v2",
   "language": "python",
   "name": "mlenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
